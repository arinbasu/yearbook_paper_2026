Use of generative AI in personalized health guidance for patients and in the development of case studies for medical education (Marcia)

Application of Generative AI in personalized health guidance

Patients’ and caregivers’ difficulties in understanding health-related guidance compromise treatment quality due to misalignment in communication between healthcare professionals and patients. Lower levels of patient understanding are associated with greater difficulty in maintaining disease control when compared with clinically stable patients. These disparities are reflected in multiple dimensions, including comprehension of medical terminology; understanding of medical and general health recommendations; quality of physician–patient and caregiver relationships; treatment adherence; continuity of chronic disease management; and the ability to distinguish between reliable and misleading health information.
In this context, Generative Artificial Intelligence (GenAI) emerges as a potential alternative to support both the development of guidance materials for patients, caregivers, and healthcare professionals and the provision of tailored recommendations for these populations. Its current applications include digital health coaching, chronic disease support, diagnostic assistance, and the mediation of patient–provider communication through personalized guidance, ranging from lifestyle recommendations to clinical risk notifications [1–5].
These solutions enable scalability, contextualization, and patient-centered guidance aligned with individual needs and characteristics, thereby increasing patient engagement and improving the assessment of communication effectiveness between healthcare professionals and patients or caregivers [1,4,5].
The development of such solutions relies on the integration of multiple technological components, including large language models (LLMs) [7], retrieval systems [6], personalized predictive models [1], knowledge representations (e.g., knowledge graphs) [3,4], and multimodal sensor fusion approaches [5]. These technologies are typically combined in layered architectures designed to balance personalization and system safety.
System safety remains one of the primary challenges of these approaches, as evaluating the correctness, reliability, and clinical appropriateness of the content and guidance delivered to users is inherently complex. Clinical validation of AI-generated guidance is particularly challenging when addressing patients holistically, especially given the wide range of possible combinations of coexisting comorbidities. Despite these challenges, the adoption of such applications appears inevitable. Consequently, there is a pressing need for the development of robust, safe-by-design methodologies for both the construction and clinical validation of GenAI-based digital health applications.

