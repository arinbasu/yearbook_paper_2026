## List of All Inputs in the form of thoughts and essays by members of the Telehealth Working Group of IMIA

## Generative AI integration with Telehealth
(IH)

Definition of telehealth
Scope of telehealth and scope of generative AI - overlaps at all stages.
Examples of where generative AI could/is working with telehealth
Triage
Support
Documentation
Radiology
Images - diagnostics (eyes, skin)
Workflow
Remote patient monitoring processing
Chatbots
Personalisation of care
Patient empowerment
Integration of IoT 
Increase access to clinical trials
Public health
Concerns
	Algorithmic bias
	Data privacy and security
	Validation of tools
	Governance
Inequity impact
Disparities in outcomes impact

Rossi M, Rehman S. Integrating Artificial Intelligence Into Telemedicine: Evidence, Challenges, and Future Directions. Cureus. 2025 Aug 23;17(8):e90829. doi: 10.7759/cureus.90829. PMID: 40988810; PMCID: PMC12453293.

Wah J. N. K. (2025). Revolutionizing e-health: the transformative role of AI-powered hybrid chatbots in healthcare solutions. Frontiers in public health, 13, 1530799. https://doi.org/10.3389/fpubh.2025.1530799\\  

Nazir, A., Nazir, A., Shah Wali Jamal, M., Sadiq, S. U. R., Aman, S., Mustapha, M. J., Lawal, S. O., AbdulKareem, M. O., & Bamigbola, M. F. (2025). Wearable Technology and Its Potential Role in Cardiovascular Health Monitoring and Disease Management. Health science reports, 8(11), e71486. https://doi.org/10.1002/hsr2.71486

Efstathia Andrikopoulou,
Chapter 13 - The rise of AI in telehealth,
Editor(s): Andrew M. Freeman, Ami B. Bhatt,
Emerging Practices in Telehealth,
Academic Press,
2023,
Pages 183-207,
ISBN 9780443159800,
https://doi.org/10.1016/B978-0-443-15980-0.00011-9.

## Generative AI to advance telehealth (CK)
Generative AI can support the overall goal of telehealth: better health outcomes over a distance. The IMIA Telehealth WG has previously described how telehealth can support diverse health system needs, including patient-centered care, education, and public health management (Kuziemsky et al., 2018; Basu et al., 2021). During the COVID-19 pandemic, we saw telehealth expand beyond clinical care. Examples include patient education, supply chain management, and health workforce management (Basu et al., 2021). Generative AI could enhance our ability to deliver on all of those types of telehealth. 
 Our WG has described three telehealth patterns to support patient-centered care delivery: one-way, two-way, and multidimensional (Kuziemsky et al., 2018).  A common theme in our previous work is that information management is a core task for effective patient-centered telehealth.  Telehealth often requires collating and analyzing data from a range of sources and formats. Generative AI could play a key role in supporting Telehealth delivery at the micro, meso, and macro levels to provide context-specific, culturally appropriate care. Generative AI can augment telehealth services by facilitating the collection, analysis, and presentation of data from diverse sources, including symptom and diagnostic data (Ebnali et al., 2025; Pool et al., 2025) as part of delivering patient centered care (Tesfaye et al., 2026). 
However, as with any type of health information technology, we must remember that telehealth is only a means of supporting health system outcomes. Generative AI models and tools to support telehealth must be developed in consultation with end users, including patients, clinicians, and administrators. We cannot just accelerate the development of Generative AI models without due diligence in developing, evaluating, and implementing them with necessary oversight at all levels, including patient, clinical, administrative, sociotechnical, and ethical, to name a few. Telehealth implementation is an iterative learning health system, and Generative AI models must be continually evaluated to grow and evolve as health systems change. 

## AI-Augmented Telemedicine for Primary Care: Opportunities and Risks (GK)

Primary care serves as the foundation of healthcare systems worldwide, providing first-contact, continuous, comprehensive, and coordinated care [1,2]. With increasing disease burden, aging populations, and workforce shortages, primary care systems are under significant pressure to deliver high-quality services efficiently [3]. Telemedicine has emerged as an important strategy to address these challenges by enabling remote consultations, monitoring, and follow-up care [4].

In recent years, Artificial Intelligence (AI) has been increasingly integrated into telemedicine platforms, giving rise to AI-augmented telemedicine. AI technologies—including machine learning, natural language processing, computer vision, and predictive analytics—are now being used to support clinical decision-making, automate administrative tasks, and enhance patient engagement [5,6]. In primary care, these tools are applied in areas such as symptom assessment, triage, diagnosis support, risk stratification, chronic disease management, and patient education [7].

The COVID-19 pandemic accelerated the adoption of telemedicine globally and highlighted the potential role of AI in supporting remote healthcare delivery [8]. Many healthcare systems rapidly deployed digital platforms enhanced with AI-driven features to manage large patient volumes, monitor disease progression, and optimize resource allocation [9]. This rapid expansion demonstrated both the promise and the limitations of AI-supported telehealth services [10].

In low- and middle-income countries (LMIC, including Sri Lanka, AI-augmented telemedicine offers additional opportunities to address healthcare access gaps, shortages of specialists, and geographical barriers [11,12]. By enabling remote expert consultations and automated clinical support, AI-based systems may strengthen primary care capacity and improve service equity [13]. However, infrastructural limitations, regulatory weaknesses, and workforce skill gaps pose major challenges to implementation [14].

Despite growing interest, the integration of AI into telemedicine raises important ethical, legal, and safety concerns. Issues such as data privacy, informed consent, algorithmic transparency, liability, and bias have become central to discussions on digital health governance [15,16]. Furthermore, overreliance on automated systems may undermine clinical judgment and patient-provider relationships [17].

Given these developments, there is a need for a balanced and evidence-based assessment of AI-augmented telemedicine in primary care. Understanding both its benefits and risks is essential for policymakers, healthcare providers, and system developers. This mini-review aims to synthesize current evidence on the opportunities and risks of AI-enabled telemedicine in primary care and to highlight key considerations for safe and effective implementation.

Starfield B, Shi L, Macinko J. Contribution of primary care to health systems and health. Milbank Q. 2005;83(3):457-502.
World Health Organization. Operational framework for primary health care: transforming vision into action. Geneva: WHO; 2020.

Jorge C. Primary care: The foundation of effective healthcare delivery. Arch Gen Intern Med. 2024;8(6):261.

Haleem A, Javaid M, Singh RP, Suman R. Telemedicine for healthcare: Capabilities, 6. features, barriers, and applications. Sens Int. 2021;2:100117.

Amjad A, Kordel P, Fernandes G. A review on innovation in healthcare sector (telehealth) through artificial intelligence. Sustainability. 2023;15(8):6655.

Bajwa J, Munir U, Nori A, Williams B. Artificial intelligence in healthcare: transforming the practice of medicine. Future Healthc J. 2021;8(2):e188-e194.

Yousefi F, et al. Opportunities, challenges, and requirements for artificial intelligence implementation in primary health care: A systematic review. BMC Prim Care. 2025;26:196.

Monaghesh E, Hajizadeh A. The role of telehealth during COVID-19 outbreak: a systematic review. BMC Public Health. 2020;20(1):1144.

Gunasekeran DV, et al. Digital health during COVID-19: lessons from operationalising new technologies and platforms in low-and middle-income countries. Lancet Digit Health. 2021;3(2):e113-e122.

Shuaib A. Transforming healthcare with AI: Promises, pitfalls, and pathways forward. Int J Gen Med. 2024;17:1765-1771.

Ministry of Health Sri Lanka. National Digital Health Blueprint for Sri Lanka. Colombo: MoH; 2023.

Yousef KM, Schmollgruber S. Artificial Intelligence in Low- and Middle-Income Countries: Reducing the Gaps in Health Care, Research, and Education. Int J Crit Care. 2024;18(2):1-3.

Perera R, et al. Systematic literature review on AI chatbot solution for medical practitioner adoption in Sri Lanka. ResGate [Preprint]. 2025.

Kuziemsky C, et al. Role of Artificial Intelligence within the Telehealth Domain. Yearb Med Inform. 2019;28(1):35-40.

Pool J, Indulska M, Sadiq S. Large language models and generative AI in telehealth: a responsible use lens. J Am Med Inform Assoc. 2024;31(9):2125-2136.

Smith A, Jones B. Ethical and Legal Challenges in AI-Driven Healthcare: Patient Privacy, Data Security, and Compliance. Int J Innov Res Sci Eng Technol. 2024;13(8):15216.

Passi S, Vorvoreanu M. Overreliance on AI: Literature review. Microsoft Research; 2022.


## Building Trust in AI-Enabled Telemedicine: Legal, Ethical, and Professional Perspectives (PR)

## Explainability and Patient Trust in AI-generated Diagnoses, Interventions and Treatment Plans (KV)

## Use of generative AI in personalized health guidance for patients and in the development of case studies for medical education (MI)

Application of Generative AI in personalized health guidance

Patients’ and caregivers’ difficulties in understanding health-related guidance compromise treatment quality due to misalignment in communication between healthcare professionals and patients. Lower levels of patient understanding are associated with greater difficulty in maintaining disease control when compared with clinically stable patients. These disparities are reflected in multiple dimensions, including comprehension of medical terminology; understanding of medical and general health recommendations; quality of physician–patient and caregiver relationships; treatment adherence; continuity of chronic disease management; and the ability to distinguish between reliable and misleading health information.
In this context, Generative Artificial Intelligence (GenAI) emerges as a potential alternative to support both the development of guidance materials for patients, caregivers, and healthcare professionals and the provision of tailored recommendations for these populations. Its current applications include digital health coaching, chronic disease support, diagnostic assistance, and the mediation of patient–provider communication through personalized guidance, ranging from lifestyle recommendations to clinical risk notifications [1–5].
These solutions enable scalability, contextualization, and patient-centered guidance aligned with individual needs and characteristics, thereby increasing patient engagement and improving the assessment of communication effectiveness between healthcare professionals and patients or caregivers [1,4,5].
The development of such solutions relies on the integration of multiple technological components, including large language models (LLMs) [7], retrieval systems [6], personalized predictive models [1], knowledge representations (e.g., knowledge graphs) [3,4], and multimodal sensor fusion approaches [5]. These technologies are typically combined in layered architectures designed to balance personalization and system safety.
System safety remains one of the primary challenges of these approaches, as evaluating the correctness, reliability, and clinical appropriateness of the content and guidance delivered to users is inherently complex. Clinical validation of AI-generated guidance is particularly challenging when addressing patients holistically, especially given the wide range of possible combinations of coexisting comorbidities. Despite these challenges, the adoption of such applications appears inevitable. Consequently, there is a pressing need for the development of robust, safe-by-design methodologies for both the construction and clinical validation of GenAI-based digital health applications.
[1] M. Ozolcer and S. W. Bae, “SePA: A Search-enhanced Predictive Agent for Personalized Health Coaching,” Sept. 05, 2025. [Online]. Available: https://arxiv.org/abs/2509.04752v1
[2] R. Yang et al., “Retrieval-Augmented Generation for Generative Artificial Intelligence in  Medicine,” June 2024, doi: 10.48550/arxiv.2406.12449.
[3] S. Garima, S. Morandé, and S. Shashank, “Harnessing the Power of Language Models for Intelligent Digital Health Services,” pp. 1–8, Oct. 2024, doi: 10.23919/ituk62727.2024.10772761.
[4] A. A. M. Umakanth, “Conversational GenAI agents in mobile health and fitness apps,” World Journal of Advanced Engineering Technology and Sciences, vol. 15, no. 3, pp. 1968–1980, June 2025, doi: 10.30574/wjaets.2025.15.3.1100.
[5] Goldblum et al., “An Implantable Device that Converses with Patients and Learns to Co-Manage Epilepsy.,” medRxiv : the preprint server for health sciences, 2026, doi: 10.64898/2026.01.26.26344234.
[6] Y. Chuang, R. Chang, Y. Cheng, and S. Huang, “Generative-AI Based Health Advisory System for Patients with Chronic Diseases”, [Online]. Available: https://link.springer.com/article/10.1007/s11036-025-02472-7
[7] S. Dongre, R. Chandra, and S. Agarwal, “MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease  Prediction and Personalized Recommendations using Generative AI,” July 2024, doi: 10.48550/arxiv.2407.20284.
Sorry, I couldn't write about the use of Generative AI in medical education.



## Ethical considerations of the use of generative AI in health (TM)
I was thinking of discussing some of the main ethical considerations with AI use in healthcare:
- Inequities and bias in AI data sets and training data, some populations not or poorly represented, or some populations do not have access - lack of co-design
- Hallucinations and automation bias, clinicians coming to rely on AI tools, not using critically, missing hallucinations, risk of deskilling
- Overhyping, lack of evidence, often evidence is poor quality - grand claims that AI performs as well as clinicians that are not backed by evidence, lack of 'silent trials'
- Trust - both in terms of lack of trust, and over-trusting. We could make this a larger part, given Prasad and Klaus both focus on trust. We could also look at how it may influence the provider-patient relationship in this regard: patient may have already consulted an AI model about their symptoms, ‘test’ the provider, if provider uses AI, responses may not be tailored to that specific patient, depending on population.  
- sustainability: requires large datacenters, impact on carbon emissions and water use. Compare to environmental impact of human labor, may replace some human labor. 
We could/should tailor this further to the specific use case of gen AI in telehealth. 
The Social and Algorithmic Fabric of Care: Addressing Bias and SDOH in Generative Models (Amanda Joseph)

Despite country specific and unique service delivery requirements, infrastructure and technological adoption, global health systems are facing the same conundrums and challenges such as the rise in non-communicable and communicable diseases, epidemics, pandemics, and environmental health risks [1,2]. Exacerbating these issues is the increasing demand placed on health systems caused by increasing burden of chronic disease among ageing populations, combined with healthcare workforce shortages [3-7]. Thus the strategic oversight of unnecessary expenditures, and targeted medical interventions are increasingly vital to maintain gold standard quality healthcare service delivery and provision, and positive population outcomes [4,7,8]. As such healthcare disparities are a complex phenomenon that can present in multifaceted ways, namely social determinants of health (SDOH), the World Health Organization (WHO) defines SDOH broadly as “the conditions in which people are born, grow, live, work and age, and people’s access to power, money and resources” [9]. Thus SDOH may reveal why some populations could be disproportionately impacted by chronic medical conditions and lower access to care [6,10]. Thus SDOH may reveal why some populations could be disproportionately impacted by chronic medical conditions and lower access to care [6,10,11]. For example in Australia and New Zealand (Aotearoa) health disparities exist across the Torres Strait islander, Aboriginal, and Māori peoples, when compared to non-Indigenous peoples in both countries [3, 12]. Moreover, in their report the Australian Institute of Health and Welfare (AIHW)  stated that the burden of disease among Torres Strait Islander and Aboriginal people was 2.3 times higher than that of non-Indigenous people [13]. A further analysis by the AIHW revealed that many of the disparities impacting Aboriginal and Torres Strait Islander people was attributed to SDOH such as housing, education, income and employment, and lack of culturally appropriate healthcare service in local languages [13]. Along a similar line in a recent report Health New Zealand detailed that inequalities between population groups exist, with Pacific, and Māori peoples having poorer healthcare outcomes when compared to non-Pacific and non-Māori people [14]. It was also revealed that there was a relationship between urbanicity, and life expectancy [14]. The report specified that life expectancy was higher in urban areas, and lower in rural and remote areas across New Zealand (Aotearoa) [12,14]. Further the demand on current health systems are anticipated to increase with aging populations, and chronic disease complexity (i.e., cancer, diabetes, neurocognitive disorders) [12,15].  
 
Thus, telehealth technologies can facilitate the delivery of health education, health information and healthcare services remotely, and hold great promise to alleviate the current and anticipated future strains on health systems [16-19]. Moreover, utilizing and expanding current telemedicine services which specifically enable healthcare providers to provide services remotely via video, telecommunications, and mobile technologies can reduce barriers to care. However, human-centered approaches to telehealth service design and facilitation are paramount, ensuring that technical products are usable, and meet end-users (e.g., healthcare providers, patients) needs [20-22]. However, negative unintended consequences and increased disparity can also be introduced with technological adoption, if they are not adequately designed, tested or implemented, with the appropriate stakeholders groups (e.g., patients, providers) [21,22]. As such clear criteria must be established through informative training, service agreements and along a similar line, digital innovation is adding pressure on governments and regulatory bodies, as diversified technologies are evolving at unprecedented paces [23-27]. Thus governments must balance the need to maintain sound governance, while avoiding regulatory capture which could stifle innovation, and limit scalability of telehealth service offerings [26,27]. Moreover the complexity of data aggregation and the synthesis of high quality data poses inherent risks when algorithms are not transparent (i.e., black box) and their data sources unclear. Thus, with the introduction of AI to generate real-world evidence (RWE) from available real-world data (RWD) the potential to advance healthcare data synthesis, interpretation and aggregation is unprecedented [28]. Thus the importance of establishing bias potential in RWD in the creation of AI models must be underscored, along with patient end-user disclosure of how their data will be used, stored to ensure that GenAI technologies don’t inadvertently negatively impact certain populations [28]. Further, Kioski and colleagues reference a study in which it was revealed that deep learning architectures trained on smartphone-based dermatological imagery can exhibit reduced diagnostic accuracy in patients with darker skin [28,29]. The data integrity discrepancy illustrates the importance of using appropriate and representative data across model training phases [28,29]. It is therefore vital that the datasets are indicative of the true population, AI modalities can truly revolutionize healthcare services, and the scalability of delivery however, the reliance on its increasing use should acknowledge that substantial bias exists and with the introduction of  automatization of this bias is increased and the risks of potential harms unquantifiable. Despite these perceived barriers to implementation and adoption, through collaboration and concentrated efforts among stakeholders, telehealth services using AI modalities hold promise to catalyze scalable healthcare service delivery gaps, and enhance the health and well-being of individuals [17, 30,31].  
 
References in Vancouver Style
 
1. Iyengar MS, Merchant N, Ernst K, Rains S, Arora M, Ngaybe MGB, et al. Resilience Informatics for Public Health. Stud Health Technol Inform. 2024 Jan 25;310:1276–80.
2. Sharma M, Akhter MS, Roy S, Srejon R. Future Issues in Global Health: Challenges and Conundrums. Int J Environ Res Public Health. 2025 Feb 21;22(3):325.
3. Miles M, Francis K. The Australian and New Zealand health care systems. In: Chronic care nursing: a framework for practice. Second edition. Cambridge, United Kingdom ; New York, NY: Cambridge University Press; 2019. p. 65–79.
4. Association of American Medical Colleges, GlobalData Plc. The Complexities of Physician Supply and Demand: Projections From 2021 to 2036 [Internet]. Washington, DC; 2024 [cited 2025 Sept 5]. Available from: https://www.aamc.org/media/75236/download?attachment
5. Joseph AL, Shah LM, Kushniruk A, Quintana Y. A Human-Centered Physician Journey. Stud Health Technol Inform. 2023 Jun 22;304:76-77. doi: 10.3233/SHTI230374. PMID: 37347574.
6. Joseph AL, Oladimeji, B, Monkman, H, Minshall SR, Tan MC, Quintana, Y. The Maternal HealthJourney: A Visualized Combined Experience Approach for a Learning Health System. J Particip Med. 2025 Dec 31. doi: 10.2196/82944.
7. Michaeli DT, Michaeli JC, Albers S, Michaeli T. The Healthcare Workforce Shortage of Nurses and Physicians: Practice, Theory, Evidence, and Ways Forward. Policy Polit Nurs Pract. 2024 Nov;25(4):216–27.
8. Joseph AL, Costello J, Monkman H, Quintana Y. Applying Logic to the Healthcare Journey. In: Bamgboje-Ayodele A, Prgomet M, Kuziemsky CE, Elkin P, Nøhr C, editors. Studies in Health Technology and Informatics [Internet]. IOS Press; 2023 [cited 2025 Sept 2]. Available from: https://ebooks.iospress.nl/doi/10.3233/SHTI230373.
9. World Health Organization. World Report on Social Determinants of Health Equity [Internet]. World Health Organization; 2025 May. Report No.: 248. Available from: https://www.who.int/publications/i/item/9789240107588
10.  Joseph AL, Monkman H, Minshall SR, Quintana Y. Humanizing Big Data and Detailing Social Determinants of Health via Information Visualizations. Stud Health Technol Inform. 2023 Jun 22;304:112-116. doi: 10.3233/SHTI230384. PMID: 37347582.
11.  Marmot M, Allen J, Bell R, Bloomer E, Goldblatt P; Consortium for the European Review of Social Determinants of Health and the Health Divide. WHO European review of social determinants of health and the health divide. Lancet. 2012 Sep 15;380(9846):1011-29. doi: 10.1016/S0140-6736(12)61228-8. Epub 2012 Sep 8. PMID: 22964159.
12.  Public Health Advisory Committee. Determining our Future - Social, Cultural, Economic and Commercial Determinants of Wellbeing in Aotearoa New Zealand: Actions to improve our health and wellbeing [Internet]. 2025 [cited 2025 Sept 5]. Available from: https://www.health.govt.nz/system/files/2025-08/PHAC-determining-our-future-v5.pdf
13. Australian Institute of Health and Welfare. Aboriginal and Torres Strait Islander Health Performance Framework [Internet]. 2025 June [cited 2025 Sept 5]. Available from: https://www.indigenoushpf.gov.au/getattachment/36db9308-d7ed-47b9-945c-5ceebb956528/hpf_summary-report-june-2025.pdf.
14.Health New Zealand. Life Expectancy in Aotearoa New Zealand: An Analysis of Socioeconomic, Geographic, Sex and Ethnic Variation from 2001 to 2022 [Internet]. 2024 July [cited 2025 Sept 6]. Available from: https://www.tewhatuora.govt.nz/assets/Uploads/Technical-Report-Life-Expectancy-Nov-2024-printable.pdf.
15. McDonald WM. Overview of Neurocognitive Disorders. Focus Am Psychiatr Publ. 2017 Jan;15(1):4–12.
16.  Basu A, Rajput VK, Ito M, Ranatunga P, Kuziemsky C, Kulatunga G, et al. Telehealth as a Component of One Health: a Position Paper. Yearb Med Inform. 2023 Aug;32(1):19–26.
17. Iyengar S. Mobile health (mHealth). In: Fundamentals of Telemedicine and Telehealth [Internet]. Elsevier; 2020 [cited 2025 Sept 5]. p. 277–94. Available from: https://linkinghub.elsevier.com/retrieve/pii/B9780128143094000124
18.  Lau ECH, Rajput VK, Hunter I, Florez-Arango JF, Ranatunga P, Veil KD, et al. Telehealth and Precision Prevention: Bridging the Gap for Individualised Health Strategies. Yearb Med Inform. 2024 Aug;33(1):64–9.
19. NEJM Catalyst. What is Telehealth? NEJM Catal [Internet]. 2018 Feb [cited 2025 Sept 5]; Available from: https://catalyst.nejm.org/doi/full/10.1056/CAT.18.0268.
20. Joseph AL. Human-Centered Healthcare Evaluation Using Personas and Journey Mapping Techniques. In: Kaehne A, Feather J, editors. Handbook of Health Services Evaluation [Internet]. Cham: Springer Nature Switzerland; 2025 [cited 2025 Sept 2]. p. 471–94. Available from: https://link.springer.com/10.1007/978-3-031-87869-5_25
21.  Joseph AL, Borycki E, Kushniruk A. Alert fatigue and errors caused by technology: A scoping review and introduction to the flow of cognitive processing model. Knowl Manag E-Learn Int J. 2021 Dec 30;500–21.
22.  Joseph AL, Monkman H. The Kübler-Ross Five Stages of Grief Model: A Framework for Human-Centered Health Informatics. Stud Health Technol Inform. 2025 May 12;326:70–4.
23. Choxi H, VanDerSchaaf H, Li Y, Morgan E. Telehealth and the Digital Divide: Identifying Potential Care Gaps in Video Visit Use. J Med Syst. 2022 July 30;46(9):58.
24.  Fisher K, Magin P. The telehealth divide: health inequity during the COVID-19 pandemic. Fam Pract. 2022 May 28;39(3):547–9.
25.  Australian Productivity Commission, New Zealand Productivity Commission, editors. Growing the digital economy in Australia and New Zealand: maximising opportunities for SMEs. Melbourne; 2019. 1 p. (Joint Research Report).
26. Rozenblit L, Price A, Solomonides A, Joseph AL, Koski E, Srivastava G, et al. Toward responsible AI governance: Balancing multi-stakeholder perspectives on AI in healthcare. Int J Med Inf. 2025 Nov;203:106015.
27.  Rozenblit L, Price A, Solomonides A, Joseph AL, Srivastava G, Labkoff S, et al. Towards a Multi-Stakeholder process for developing responsible AI governance in consumer health. Int J Med Inf. 2025 Mar;195:105713.
28. Koski E, Das A, Hsueh PS, Solomonides A, Joseph AL, Srivastava G, Johnson CE, Kannry J, Oladimeji B, Price A, Labkoff S, Bharathy G, Lin B, Fridsma D, Fleisher LA, Lopez-Gonzalez M, Singh R, Weiner MG, Stolper R, Baris R, Sincavage S, Naumann T, Williams T, Bui TTT, Quintana Y. Towards responsible artificial intelligence in healthcare-getting real about real-world data and evidence. J Am Med Inform Assoc. 2025 Nov 1;32(11):1746-1755. doi: 10.1093/jamia/ocaf133. PMID: 40999782; PMCID: PMC12626219.
29. Esteva, A., Kuprel, B., Novoa, R. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017). https://doi.org/10.1038/nature21056
30. Gogia S, editor. Fundamentals of telemedicine and telehealth. London ; San Diego, Calif: Academic Press, an imprint of Elsevier; 2020. 385 p.
31. Anawade PA, Sharma D, Gahane S. A Comprehensive Review on Exploring the Impact of Telemedicine on Healthcare Accessibility. Cureus. 2024 Mar;16(3):e55996

## Balancing Risks and Benefits of Generative AI Use by Community Health Workers (AM)

I. Introduction
	1.	Context: recent technological developments now enable community health workers in remote areas to have access to devices with generative AI capabilities. This opens up the opportunity for CHWs to use GenAI as they move from house to house, offering services to their communities. There is therefore a need to define the new roles and responsibilities of Community Health Workers (CHWs) in primary care and public health beyond the traditional navigator and reminder of appointments. Enabled with electronic devices with artificial intelligence built in, the new CHWs are now capable of newer tasks that are not yet formalized in the standard CHW training. There is a need to protect people and their CHWs when they begin using new technology, such as AI, in remote settings.
Objectives

Current state assessment of the capabilities of Community Health Workers

- Describe the scope of practice and typical tasks (health education, data collection, referrals)
- Measure the digital maturity of CHWs in low- and middle-resource settings
- Define Generative AI (GenAI)

Enumerate Potential Benefits of Generative AI for CHWs

- Clinical Support
-- Simplified health education materials in local languages
-- Triage guidance aligned with protocols
-- Symptom clarification and structured documentation

- Administrative Efficiency
-- Automated report creation
-- Summarization from field notes
-- Form completion and data quality assistance


- Capacity Building

-- On-demand training explanations
-- Simulation of patient counseling scenarios
-- Translation of technical guidelines into plain language

- Equity and Reach
-- Language translation for diverse communities
-- Culturally adapted messaging
-- Support for geographically isolated areas


IV. Key Risks and Concerns

1.	Clinical Safety Risks

Hallucinated or incorrect medical advice
Over-reliance and deskilling
Misalignment with national clinical guidelines

2.	Ethical and Privacy Risks
Unauthorized sharing of identifiable health data
Data retention and secondary use concerns
Informed consent limitations

3.	Bias and Equity Risks
Algorithmic bias against marginalized groups
Under-representation of local epidemiology
Language inequities

4.	Governance and Accountability Risks
Ambiguity of responsibility (CHW vs. supervisor vs. vendor)
	Lack of audit trails
Vendor lock-in and dependency

5.	Regulatory and Legal Exposure
Compliance with data protection laws
Medical liability implications
Cross-border data transfer issues

V. Risk–Benefit Framework for Decision-Making

An explicit risk-benefit framework co-designed with CHWs and their administrators can help with building awareness of the benefits and pitfalls of GenAI when used in the community setting. By jointly creating the risk registry, CHWs are more able to obtain the lens of ethical practice and apply them in their real world settings.
 
Some interventions that can be added to a pilot are identying the new tasks and classigyin them by risk levels such as

Low-risk: Converting speech to text
Moderate-risk: Summarizing patient notes
High-risk: Diagnostic or treatment recommendations

By introducing use-case classification to health workers they assimilate the risk intelligence needed to be able to independently recognize risky CHW behavior.

By ensuring that their administrators are always informed of the GenAI transactions, we are able to retain the “Human-in-the-Loop Model” and impose a mandatory supervisory review for high-risk outputs. The CHWs are then advised to follow escalation protocols in case they do not pick up the risks by themselves.

Data Governance Controls

Clear explicit de-identification requirements are co-designed with the CHWs so they can remember the spirit behind those actions. They should be allowed to play in secure sandbox environments. Administrators should be able to configure access controls and monitor the logs for non-compliance or for risky behavior..

Training and Digital Literacy

CHWs must be trained on the basics of digital health including the benefits and limits of AI. These content should be integrated into the standard  literacy modules for CHWs. The training should explicitly and clearly enumerate the do’s and dont’s of use of AI in the community. If possible, CHWs and their administrators should be able to recognize hallucination patterns.


When it comes to implementation, safeguards should be put in place such as:

Policy Framework. A formal document lists all approved and prohibited use cases. The same document can be extended to become the standard operating procedure (SOP).

Technical Safeguards. The CHWs must be given local first (or offline first) applications so they can get quality of service when they need to use the application. Clear plain language should be used when providing advice offline and all audit logs are monitored using dashboards.

Evaluation and Monitoring. A dedicated team of CHws and administrators perform continuous quality assurance by hilding regular data quality meetings, monitoring the logs and incident reported. This enables a feedback loop back to the imporevement of the system from the CHWs.

Strategic Considerations for Health Systems

With the pilot, there should be clear alignment with national digital health strategy. The pilot is not a stand alone system but integrates with existing health information systems. There should be an accompanying ferasibility and investment plan to ensure that the system receives financial support during the ramp-up period. Continuity of operations enables public trust and stronger community engagement.

Conclusion
1.	Generative AI is an important augmentation tool — but It cannot replace CHWs. TO protect both patients and the CHWs, there should be deliberate risk monitoring to prevent the harmful effects of AI (bias, hallucination, forgetfulness). In case of a pilot, a clear evaluation frameork should be co-designed with the CHWs and the data used to iterate and learn. When stable, the system can then be scaled responsibly..


## Conversational agents - SI 

Xyz 



## Enhancing Telehealth Documentation: The Role of Generative AI in Healthcare Scribes (UI)


## A word of caution - missing quality data within EHRs is a contributor to hallucinations. -some preliminary measures required (SBG)

All of AI depends on quality data. Data cannot arise in a vacuum and collection is very much a human effort, some may call it as the slowest link in the Data, Information, Knowledge, Wisdom (DIKW) pyramid. Within healthcare, time management is an issue with the doctor’s time remaining the most expensive element of care delivery. Electronic Medical Records may have arguably aided care efficiency, but that has been at the cost of less time being devoted to the patient[1], the majority being spent on documentation, and that too. From the telehealth perspective, data collection using Store and Forward Telemedicine, before the actual physician encounter by phone or video, can not only ensure better outcomes as well decrease in the time spent on care delivery. THis data can and should be added to the data pool which will assist learning of the AI system. 
Alongside detailed history taking has lately become a nearly forgotten aspect of diagnosis, more so because of the lack of time. That AI agents can be used to take detailed notes on the salient points of the history[2] is still in the nascent stages, and worth exploring further.
Using scribes to enter preliminary data even before the actual visit can be done as shown by SATHI as part of its Digital Health Assistant training program [3] is another possible solution. Making typing shortcuts or typeaheads which can make data entry smooth has been there since long, but marred by problems related to auto- correct which becomes worse during health data entry as these are uncommon terms as far as dictionary spelling is concerned. An upcoming plan currently mooted by ISO is to make healthcare graphics and icons [4] linked to standardized Health terminologies linked like SNOMED CT which will hint that the entered health term is appropriate.

References for this section
Jeremy Cox. Transition to electronic medical records slow, costly. jacksonville.com [Internet]. [cited 2010 Nov 4]. Available from: http://jacksonville.com/business/2009-03-30/story/transition_to_electronic_medical_records_speeding_up
Gogia S. BOTs for prior online clinical assessment. In: International Medical Informatics Association, editor. Medinfo 2023. Sydney: imia-medinfo.org; 2023.1.
Ramachandran A, Gogia SB, Bajaj SK, Gogia AR. Initial Experience and Evaluation of the SATHI Digital Health Assistant Program. Stud Health Technol Inform. 2025 Aug 7;329:1467–71. doi:10.3233/SHTI251082
Ma X. Developing Design Guidelines for a Visual Vocabulary of Electronic Medical Information to Improve Health Literacy. Interact Comput. 2016;28(2):151–69. doi:10.1093/iwc/iwv025




## Generative artificial intelligence in remote triage and patient self-diagnosis (KA)

Artificial intelligence (AI)–driven remote self-diagnosis tools are positioned as an entry point to health care, aiming to mitigate shortages of professionals, long waiting times, and geographic barriers, particularly in underserved and rural settings (Fan et al. 2021; Khan et al. 2025). AI chatbots and large language models (LLMs) enable patients to describe symptoms in natural language, receive preliminary diagnostic suggestions and triage advice, and obtain health education without temporal or spatial constraints, thereby functioning as a first digital contact with the health system (Fan et al. 2021; Kuroiwa et al. 2023; Xue et al. 2024).
Real‑world data from large-scale deployment of self-diagnosis chatbots show heterogeneous usage patterns across age groups and conditions, with frequent use for mild or stigmatized complaints, but also high early drop‑out rates, ludic behavior, and recurrent concerns about diagnostic accuracy and lack of actionable guidance, which threaten sustained engagement and trust (Fan et al. 2021). Experimental evaluations of LLM-based self-diagnostic support indicate inconsistencies, with better accuracy for localized orthopedic syndromes with poor performance for multifocal or complex presentations, and substantial variability across days and raters (Kuroiwa et al. 2023). Nevertheless, comparative analyses of conversational generative AI against paid orthopedic teleconsultations suggest that AI can match clinicians in logical reasoning, guidance, and overall satisfaction, and significantly surpass them in clarity and breadth of educational content, supporting its role as a scalable tool for remote counseling and patient navigation rather than a replacement for diagnostic judgment (Xue et al. 2024).
At the system level, structured frameworks for AI-enabled care delivery emphasize that remote AI-driven comprehensive community profiles must be embedded within community-tailored, hybrid models that account for digital readiness, epidemiological profiles, cultural factors, and local health priorities to avoid exacerbating inequities and algorithmic biases (Khan et al. 2025). 
In conclusion, current evidence for generative AI-based remote self-diagnosis, currently is best conceptualized as an adjunctive triage and education layer within supervised virtual care, requiring explicit design for safety netting, transparency, governance, and equity before broader clinical integration. And although a promising solution for mitigating limitations in healthcare access, could benefit from more large-scale scientific studies to evaluate its efficacy and safety.
* I had to change subjects as I could not find enough articles about the previous scope: Literature review about AI medical scribes in remote consultations
